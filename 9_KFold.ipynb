{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to K-Fold Cross-Validation\n",
    "\n",
    "In this notebook, we will explore K-Fold Cross-Validation, a popular technique for evaluating the performance of machine learning models. K-Fold Cross-Validation helps in assessing model performance by splitting the dataset into multiple training and testing sets, ensuring a more reliable estimate of model accuracy.\n",
    "\n",
    "### Key Concepts:\n",
    "- **K-Fold Cross-Validation**: How it works and why it's used.\n",
    "- **Performance Metrics**: Evaluating models based on multiple training/test splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier  # Example model\n",
    "from sklearn.metrics import accuracy_score  # For evaluating performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Loading Data and Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('expand_frame_repr', False)\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Combine the data into a DataFrame\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "\n",
    "# Add the target variable to the DataFrame\n",
    "iris_df['target'] = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris_df.drop('target', axis=1) # Features\n",
    "y = iris_df['target'] # Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model (K-Nearest Neighbors in this case)\n",
    "model = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Splitting the Data into Train (80%) and Test (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Applying the Resampling Procedure of Cross-Validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is K-Fold Cross-Validation?**\n",
    "\n",
    "K-Fold Cross-Validation is a technique that splits the dataset into 'K' subsets (or folds). The model is trained on 'K-1' subsets and tested on the remaining fold. This process is repeated 'K' times, with each fold serving as the test set once. The average performance across all folds gives a better estimate of the model's accuracy.\n",
    "\n",
    "In this notebook, we will use 3-Fold Cross-Validation although the usual practice is 5 or 10 folds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "\n",
      "\u001b[31mTrain Index:\u001b[0m \n",
      "[  1   2   3   5   6   7   8  13  14  16  17  19  20  21  23  25  27  28\n",
      "  29  32  33  34  35  37  38  39  41  43  46  48  49  50  51  52  54  57\n",
      "  58  59  60  61  63  66  67  68  69  71  72  74  75  77  79  80  81  82\n",
      "  83  84  85  86  87  90  92  93  94  95  98  99 100 101 102 103 105 106\n",
      " 108 111 112 113 115 116 117 119]\n",
      "\n",
      "\u001b[31mTest Index:\u001b[0m \n",
      "[  0   4   9  10  11  12  15  18  22  24  26  30  31  36  40  42  44  45\n",
      "  47  53  55  56  62  64  65  70  73  76  78  88  89  91  96  97 104 107\n",
      " 109 110 114 118]\n",
      "\n",
      "Fold 1 Accuracy: 0.95\n",
      "\n",
      "Fold 2:\n",
      "\n",
      "\u001b[31mTrain Index:\u001b[0m \n",
      "[  0   1   2   4   9  10  11  12  14  15  18  20  21  22  23  24  26  29\n",
      "  30  31  32  36  37  40  41  42  44  45  47  48  51  52  53  55  56  57\n",
      "  58  59  60  61  62  63  64  65  70  71  73  74  75  76  78  79  81  82\n",
      "  86  87  88  89  91  92  93  96  97  99 101 102 103 104 105 106 107 108\n",
      " 109 110 112 114 115 116 118 119]\n",
      "\n",
      "\u001b[31mTest Index:\u001b[0m \n",
      "[  3   5   6   7   8  13  16  17  19  25  27  28  33  34  35  38  39  43\n",
      "  46  49  50  54  66  67  68  69  72  77  80  83  84  85  90  94  95  98\n",
      " 100 111 113 117]\n",
      "\n",
      "Fold 2 Accuracy: 0.95\n",
      "\n",
      "Fold 3:\n",
      "\n",
      "\u001b[31mTrain Index:\u001b[0m \n",
      "[  0   3   4   5   6   7   8   9  10  11  12  13  15  16  17  18  19  22\n",
      "  24  25  26  27  28  30  31  33  34  35  36  38  39  40  42  43  44  45\n",
      "  46  47  49  50  53  54  55  56  62  64  65  66  67  68  69  70  72  73\n",
      "  76  77  78  80  83  84  85  88  89  90  91  94  95  96  97  98 100 104\n",
      " 107 109 110 111 113 114 117 118]\n",
      "\n",
      "\u001b[31mTest Index:\u001b[0m \n",
      "[  1   2  14  20  21  23  29  32  37  41  48  51  52  57  58  59  60  61\n",
      "  63  71  74  75  79  81  82  86  87  92  93  99 101 102 103 105 106 108\n",
      " 112 115 116 119]\n",
      "\n",
      "Fold 3 Accuracy: 0.95\n",
      "\n",
      "Average cross-validation accuracy on training data: 0.95\n"
     ]
    }
   ],
   "source": [
    "color_red, color_reset = \"\\033[31m\", \"\\033[0m\"\n",
    "\n",
    "k = 3\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "accuracy_list = []\n",
    "\n",
    "# Iterate through the k splits\n",
    "for fold_num, (train_index, test_index) in enumerate(kf.split(X_train)):\n",
    "    print(f\"Fold {fold_num+1}:\\n\")\n",
    "    print(f\"{color_red}Train Index:{color_reset} \\n{train_index}\\n\")\n",
    "    print(f\"{color_red}Test Index:{color_reset} \\n{test_index}\\n\")\n",
    "    # Split the data into training and testing sets for this fold\n",
    "    X_train1, X_test1 = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_train1, y_test1 = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    # Train the model on this fold's training data\n",
    "    model.fit(X_train1, y_train1)\n",
    "    \n",
    "    # Evaluate the model on this fold's validation data\n",
    "    y_pred = model.predict(X_test1)\n",
    "    fold_accuracy = accuracy_score(y_test1, y_pred)\n",
    "    accuracy_list.append(fold_accuracy)\n",
    "    print(f\"Fold {fold_num+1} Accuracy: {accuracy_list[fold_num]:.2f}\\n\")\n",
    "\n",
    "average_fold_accuracy = sum(accuracy_list) / len(accuracy_list)\n",
    "print(f'Average cross-validation accuracy on training data: {average_fold_accuracy:.2f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Final Model Training:\n",
    "\n",
    "After cross-validation, the model is trained on the entire training data (X_train and y_train).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6. Evaluation on the Test Set:\n",
    "\n",
    "Finally, we evaluate the trained model on the test set (X_test and y_test), which was never seen during cross-validation.\n",
    "This test accuracy reflects the model's ability to generalize to new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f'Test accuracy: {test_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of the Results:\n",
    "- **Cross-Validation Accuracy (0.95):**\n",
    "\n",
    "    - Cross-validation accuracy represents the model's performance during K-Fold Cross-Validation, which evaluates how well the model generalizes on different subsets of the **training data**.\n",
    "    - An accuracy of 0.95 (95%) indicates that the model performs well on the training set's different folds and generalizes well across these subsets.\n",
    "\n",
    "- **Test Accuracy (1.00):**\n",
    "\n",
    "    - Test accuracy represents the model's performance on the held-out test set. This test set was never seen by the model during training or cross-validation, so this is the final measure of how well the model generalizes to completely unseen data.\n",
    "    - A test accuracy of 1.00 (100%) means the model correctly classified all the test set samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "The model is performing extremely well, with a cross-validation accuracy of 95% and a perfect test accuracy of 100%. This indicates that the model has learned the structure of the Iris dataset very well and is likely to generalize effectively to similar data. However, the perfect test score could be a reflection of the simplicity of the Iris dataset, and achieving this in more complex, real-world data may not be as easy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataanalytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
